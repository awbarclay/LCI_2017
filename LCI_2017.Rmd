---
title: "Lower Cook Inlet Chinook marine sport harvest MSA"
author: "Andy Barclay"
date: "June 14, 2018"
output: html_document
---
##Set up workspace
###Get functions and load tidy packages
```{r workspace setup, echo=TRUE}

source("C:\\Users\\awbarclay\\Documents\\R\\GitHubCloneFunctions.R")#GCL functions
source("V:\\Analysis\\Staff\\Andy Barclay\\R\\New Functions\\WorkspaceFolders.GCL.R")#A function I wrote

library("tidyverse")

```

###Create output folders 
```{r create folders, echo=TRUE, message=FALSE}
#WorkspaceFolders.GCL(Folders=c("Output","objects","rubias"),Subfolders=list(rubias=c("baseline","mixture","output")),wd=getwd())

```

###Create locus control and get genotype data
```{r locus control, echo=TRUE}

#CreateLocusControl.GCL(markersuite = "LCI_Chinook_43SNPs", username ="awbarclay", password = password)#Locus control

sillyvec<-c("KCIMHO17","KCIMAP17","KCIMDC17")

#LOKI2R.GCL(sillyvec=sillyvec,username="awbarclay",password)#Pull Data from LOKI

#save.image("V:/Analysis/2_Central/Chinook/Lower Cook Inlet/LCI_2017/LCI_2017.Rdata")

load("V:/Analysis/2_Central/Chinook/Lower Cook Inlet/LCI_2017/LCI_2017.Rdata")
```

###Create initial locus object
```{r initial locus object}

loci <- LocusControl$locusnames
loci

```

##Data cleanup
###Check initial sample size
```{r initial sample size, echo=TRUE}

silly_N<-function(sillyvec){sapply(sillyvec,function(silly){get(paste0(silly,".gcl"))$n})}#Function for sample sizes

ColSize<-data.frame(row.names = sillyvec)
ColSize$Original_N <-silly_N(sillyvec)
ColSize

```

###Check genotypes by locus
This is the proportion of the samples with genotypes by locus
```{r sample size by locus}

SampSizeByLoc<-as.tibble(SampSizeByLocus.GCL(sillyvec,loci)/ColSize$Original_N) %>% 
  mutate(Collection=sillyvec) %>% 
  select(Collection,everything()) %>% 
  gather(key=Locus,value="Proportion",-Collection)

head(SampSizeByLoc)
```
#Heatmap to check for holes
```{r heatmap of genotype holes, fig.height=24, fig.width=20}

SampSizeByLoc %>% 
  ggplot(aes(Collection,Locus,fill=Proportion))+
  geom_tile()

```
###Removing individuals with <80% of loci with gentotypes
Fish that have gentoypes for less than 80% of loci are likely to have poor quality DNA and might introduce gentotyping errors into the mixture data and reduce the accruacy of the mixed stock analysis (MSA)
```{r missloci,echo=TRUE}

MissLOCI=RemoveIndMissLoci.GCL(sillyvec=sillyvec,proportion=0.8)
MissLOCI

ColSize$AfterMissLoci_N <- silly_N(sillyvec)
ColSize

```

###Check for duplicate individuals and remove them
Fish with 99% of scores that match
```{r dupckeck, echo=TRUE, message=FALSE}

dupcheck<-CheckDupWithinSilly.GCL(sillyvec=sillyvec,loci=loci,quantile=NULL,minproportion=0.99)

```
```{r remove duplicate fish,results="hide"}

DupsRemoved<-RemoveDups.GCL(dupcheck)#Remove one of the duplicates

```
```{r final sample size}
ColSize$Final_N <- silly_N(sillyvec)
ColSize

```
##Set up baseline
###Get objects from baseline workspace
```{r baseline objects, message=FALSE}

attach("V:/Analysis/2_Central/Chinook/Lower Cook Inlet/2015/Baseline/LowerCIChinook2015Baseline_new.RData")

PooledNames211<-PooledNames211


#loci43<-loci43 this list of loci contains PSMB1 and not NRP, drop PSMB1 since it was not run on the mixture analysis project 
loci42<-loci43[-29]

```
###Create rubias baseline
```{r create baseline}

groups<- c("Outside_CI","WestSusitna","KnikTurnagain","Kenai","SKenaiPen")

groupvec <- c(rep(1,63),rep(2,29),rep(3,8),rep(4,12),rep(5,6),rep(1,93))

rubias_baseline <- create_rubias_baseline(sillyvec=PooledNames211,loci = loci42, groupvec = groupvec, group_names = groups, path = "rubias/baseline", baseline_name = "LCI_211pops_42loci")

detach(pos=match(x="file:V:/Analysis/2_Central/Chinook/Lower Cook Inlet/2015/Baseline/LowerCIChinook2015Baseline_new.RData",table=search()))#Detach from baseline data.

```
###Replace zero with NA some baseline scores
The old baseline data contains NAs and zeros for some scores. Eric Anderson's github page for rubias says that missing data should be NAs. Rubias determines the ploidy of a marker by looking for missing data in one of the alleles. Rubias was giving this error message:"Error in get_ploidy_from_frame(tmp) : Bailing out due to single gene copies being missing data at non-haploid loci." 

I think the cause of the error is that there are scores for allele 2 of C3N3 in some pops. Look like this is may fault as I filled in genotypes for some collections in areas where we know C3N3 is fixed, but I accidentally added scores to the second allele in some pops durring the baseline analysis.

```{r make NAs zero, results="hide"}

loci_allele<-dimnames(rubias_baseline)[[2]]

for(loc in loci_allele){
  
  rubias_baseline[,loc]<-replace(rubias_baseline[,loc],rubias_baseline[,loc]==0,NA)
  
}

rubias_baseline[,"Ots_C3N3.1"]=as.character(NA)
  
write_excel_csv(rubias_baseline,"rubias/baseline/LCI_211pops_42loci_base.csv")

```

##Setup mixtures
###Create vector of mixture names
```{r mixvec, echo=FALSE}

mixvec<-c("LCI_Summer","LCI_Winter","UCI_Early","UCI_Late")  

```

###Get mixture IDs from attributes and create mixture .gcl objects
```{r attributes table}
attr<-bind_rows(set_names(lapply(sillyvec,function(silly){as.tibble(get(paste0(silly,".gcl"))$attributes)}),sillyvec))
attr
```
####LCI_winter
```{r LCI_winter,message=FALSE,result="hide"}

LCI_Winter_IDs<-set_names(lapply(sillyvec,function(silly){
  
  attr %>% filter(CAPTURE_LOCATION=="LCI_Winter",SILLY_CODE==silly) %>% 
    select(FK_FISH_ID) %>% 
    as_vector() %>% 
    as.character()

}),sillyvec) %>% 
  purrr::compact()
  

PoolCollections.GCL(collections=names(LCI_Winter_IDs),loci = loci42, IDs=LCI_Winter_IDs,newname = "LCI_Winter")
  
```
####LCI_Summer_IDs
```{r LCI_Summer_IDs,message=FALSE,result="hide"}

LCI_Summer_IDs<-set_names(lapply(sillyvec,function(silly){
  
  attr %>% filter(CAPTURE_LOCATION=="LCI_Summer",SILLY_CODE==silly) %>% 
    select(FK_FISH_ID) %>% 
    as_vector() %>% 
    as.character()

}),sillyvec) %>% 
  purrr::compact()

PoolCollections.GCL(collections=names(LCI_Summer_IDs),loci = loci42,IDs=LCI_Summer_IDs,newname = "LCI_Summer")

```

####UCI_Early_IDs
```{r UCI_Early_IDs,message=FALSE,result="hide"}

UCI_Early_IDs<-set_names(lapply(sillyvec,function(silly){
  
  attr %>% filter(CAPTURE_LOCATION=="UCI_Early",SILLY_CODE==silly) %>% 
    select(FK_FISH_ID) %>% 
    as_vector() %>% 
    as.character()

}),sillyvec) %>% 
  purrr::compact()

PoolCollections.GCL(collections=names(UCI_Early_IDs),loci = loci42,IDs=UCI_Early_IDs,newname = "UCI_Early")

```

####UCI_Late_IDs
```{r UCI_Late_IDs,message=FALSE,result="hide"}

UCI_Late_IDs<-set_names(lapply(sillyvec,function(silly){
  
  attr %>% filter(CAPTURE_LOCATION=="UCI_Late",SILLY_CODE==silly) %>% 
    select(FK_FISH_ID) %>% 
    as_vector() %>% 
    as.character()

}),sillyvec) %>% 
  purrr::compact()

PoolCollections.GCL(collections=names(UCI_Late_IDs),loci = loci42,IDs=UCI_Late_IDs,newname = "UCI_Late")

```

####Check mixture sample sizes
```{r sample size check}

silly_N(sillyvec=mixvec)

```

####Create rubias mixtures
```{r rubias mixtures,results="hide"}

rubias_mixtures <- create_rubias_mixture(sillyvec = mixvec, loci = loci42, path = "rubias/mixture")

loci_allele<-dimnames(rubias_mixtures)[[2]]

for(loc in loci_allele){
  
  rubias_mixtures[,loc]<-replace(rubias_mixtures[,loc],rubias_mixtures[,loc]==0,NA)
  
}
  
write_excel_csv(x=rubias_mixtures,path="rubias/mixture/rubias_mixtures.csv")
```

##Mixture Analysis
###Analyze mixtures in rubias
Analyzing mixtures with bias correction (method="PB") for 25,000 iterations (reps), burning the first 5,000 iterations (burn_in), and thining (sample_int_Pi) by 10 to reduce the size of the results objects.
```{r anlyze mixtures, results="hide",eval=FALSE}

run_rubias_mixture(reference=rubias_baseline, mixture=rubias_mixtures, gen_start_col=5, method = "PB", 
                   alle_freq_prior = list(const_scaled = 1), reps = 25000, burn_in = 5000, 
                   pb_iter = 100, sample_int_Pi = 10, pi_prior_pseudo_count_sum = 1, 
                   path = "rubias/output")

```

###Get reporting group traces
Reading in the rubias traces from .csv files
```{r get results,message=FALSE}

repunit_trace<-set_names(lapply(mixvec,function(mix){
  read_csv(paste0("rubias/output/",mix,"_repunit_trace.csv")) %>% 
    mutate(mixture_collection=mix) %>% 
    gather(key="repunit",value="repunit_ppn",Outside_CI,WestSusitna,KnikTurnagain,Kenai,SKenaiPen,-sweep)
  }),mixvec) %>% 
    bind_rows()
  
repunit_trace

```

###Summarize reporting group traces
```{r sum traces,message=FALSE}

mix.sum.mc<-repunit_trace %>% 
  mutate(mixture_collection=factor(mixture_collection,levels=mixvec),repunit=factor(repunit,levels=groups)) %>% 
  group_by(mixture_collection,repunit) %>% 
  summarise(pi_mean = mean(repunit_ppn),
            lo5CI = quantile(repunit_ppn, probs = 0.05),
            hi95CI = quantile(repunit_ppn, probs = 0.95),
            pi_median = quantile(repunit_ppn, probs = 0.5)) %>% 
  mutate(method="MCMC") %>% 
  ungroup()

mix.sum.mc

```

###Apply the bias correction
```{r get bias corrected estimates,message=FALSE}

mix.mean.pb<-set_names(lapply(mixvec,function(mix){
  read_csv(paste0("rubias/output/",mix,"_bias_corr.csv"))
  }),mixvec) %>% 
    bind_rows() %>% 
  mutate(mixture_collection=factor(mixture_collection,levels=mixvec),repunit=factor(repunit,levels=groups),method="PB")

mix.mean.pb

```
```{r apply bias correction to mcmc}

corr<-mix.mean.pb$bs_corrected_repunit_ppn-mix.sum.mc$pi_mean#Bias correction

mix.sum.pb<-mix.sum.mc %>% 
  mutate(mixture_collection=mixture_collection,
         repunit=repunit,
         pi_mean=pmin(pmax(pi_mean+corr,0),1),
         lo5CI=pmin(pmax(lo5CI+corr,0),1),
         hi95CI=pmin(pmax(hi95CI+corr,0),1),
         pi_median=pmin(pmax(pi_median+corr,0),1),
         method="PB")

mix.sum.pb
```
###Combine MCMC and PB method results
```{r bind MCMC and PB}

mix.sum<-bind_rows(mix.sum.mc,mix.sum.pb)

```

##Plot results
###Set up group colors
```{r group colors}

GrCol<-set_names(c("blue","forestgreen","orange","cyan","red"),groups)
GrCol
```
###Plot MCMC and PB estimates side by side
Looks like the bias correction didn't change the estimates substantially. Prehapse bias correction is not necessary for this baseline and reporting groups.
```{r mcmc and pb plots, message=FALSE, fig.height=10, fig.width=8}

mix.sum%>% 
  ggplot(aes(x=repunit, y = pi_mean, fill =repunit)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  geom_bar(stat="identity",position = "dodge") +
  geom_errorbar(aes(ymin = lo5CI, ymax = hi95CI, width = 0.3), position = "dodge")+
  scale_fill_manual(name = "Reporting Group", values = GrCol) +
  facet_wrap(~ mixture_collection+method,ncol=2) +
  ylab("Proportion")+
  xlab("Reporting Group")+
  ggtitle(label="2017 Cook Inlet Marine Sport Harvest Compostion",subtitle = "Markov Chain Monte Carlo (MCMC) and parametric boostrap bias corrected (PB) estimates")

ggsave(filename = "Output/2017 Cook Inlet Marine sport fishery Chinook salmon harvest compostions_MCMCvsPB.pdf",device="pdf")
```

###Plot only MCMC estimates
The biase correction didn't add much so plotting the MCMC esimates on their own. I'll send these to Carol Kerkvliet.
```{r mcmc plots, message=FALSE, fig.height=10, fig.width=8}

mix.sum%>% 
  filter(method=="MCMC") %>% 
  ggplot(aes(x=repunit, y = pi_mean, fill =repunit)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  geom_bar(stat="identity",position = "dodge") +
  geom_errorbar(aes(ymin = lo5CI, ymax = hi95CI, width = 0.3), position = "dodge")+
  scale_fill_manual(name = "Reporting Group", values = GrCol) +
  facet_wrap(~ mixture_collection,ncol=2) +
  ylab("Proportion")+
  xlab("Reporting Group")+
  ggtitle(label="2017 Cook Inlet Marine Sport Harvest Compostion")

ggsave(filename = "Output/2017 Cook Inlet Marine sport fishery Chinook salmon harvest compostions.pdf",device="pdf")
```
##Table the results
```{r table results}

```

